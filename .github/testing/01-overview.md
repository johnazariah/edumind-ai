# Testing Overview & Philosophy

**Purpose:** Understand EduMind.AI's testing strategy, architecture, and quality standards.

**Audience:** All developers working on the project.

---

## üéØ Testing Strategy

### Our Testing Philosophy

EduMind.AI follows a **comprehensive, multi-layered testing approach** that balances:

- **Speed:** Fast feedback during development
- **Confidence:** High coverage of critical paths
- **Maintainability:** Tests that remain valuable over time
- **Pragmatism:** Right level of testing for each component

We believe:

‚úÖ **Tests are documentation** - They show how code should be used  
‚úÖ **Fast tests matter** - Quick feedback enables rapid iteration  
‚úÖ **Integration tests catch real bugs** - Unit tests alone aren't sufficient  
‚úÖ **Coverage is a guide, not a goal** - 100% coverage doesn't mean bug-free  
‚úÖ **Flaky tests must be fixed or removed** - Unreliable tests erode confidence

---

## üèóÔ∏è Test Architecture

### The Test Pyramid

We follow the test pyramid with adjusted proportions for our AI-enhanced system:

```
         /\           E2E & UI Tests
        /  \          ‚Ä¢ Full user workflows
       / 5% \         ‚Ä¢ Browser automation
      /______\        ‚Ä¢ ~5% of total tests
     /        \       
    / AI/Agent \      AI & Agent Tests
   /    15%     \     ‚Ä¢ Ollama integration
  /              \    ‚Ä¢ Question generation
 /________________\   ‚Ä¢ Multi-agent orchestration
/                  \  
/   Integration     \ Integration Tests
/       30%         \ ‚Ä¢ API endpoints
/____________________\ ‚Ä¢ Database operations
/                     \
/      Unit Tests      \
/         50%           \
/_______________________\

Total: ~1000+ tests across all layers
```

### Test Project Structure

```
tests/
‚îú‚îÄ‚îÄ AcademicAssessment.Tests.Unit/          [~500 tests, <10s runtime]
‚îÇ   ‚îú‚îÄ‚îÄ Models/                             Domain model behavior
‚îÇ   ‚îú‚îÄ‚îÄ Repositories/                       Repository logic (InMemory DB)
‚îÇ   ‚îú‚îÄ‚îÄ Common/                             Utilities and helpers
‚îÇ   ‚îú‚îÄ‚îÄ Analytics/                          Analytics calculations
‚îÇ   ‚îî‚îÄ‚îÄ Orchestration/                      Agent coordination logic
‚îÇ
‚îú‚îÄ‚îÄ AcademicAssessment.Tests.Integration/   [~300 tests, <60s runtime]
‚îÇ   ‚îú‚îÄ‚îÄ Controllers/                        API endpoint integration
‚îÇ   ‚îú‚îÄ‚îÄ Database/                           Real PostgreSQL tests
‚îÇ   ‚îî‚îÄ‚îÄ Fixtures/                           Shared test infrastructure
‚îÇ
‚îú‚îÄ‚îÄ AcademicAssessment.Tests.UI/            [~50 tests, <5min runtime]
‚îÇ   ‚îî‚îÄ‚îÄ Workflows/                          End-to-end user scenarios
‚îÇ
‚îú‚îÄ‚îÄ AcademicAssessment.Tests.Performance/   [~20 tests, <10min runtime]
‚îÇ   ‚îî‚îÄ‚îÄ Load/                               Performance and stress tests
‚îÇ
‚îî‚îÄ‚îÄ coverlet.runsettings                    Coverage configuration
```

---

## üìä Testing Standards

### Coverage Goals

| Component | Target | Rationale |
|-----------|--------|-----------|
| **Domain Models** | 90%+ | Core business logic must be thoroughly tested |
| **Repositories** | 80%+ | Data access is critical for correctness |
| **API Controllers** | 80%+ | External contract must be reliable |
| **Services/Agents** | 75%+ | Business logic needs strong coverage |
| **Blazor Components** | 60%+ | UI logic harder to test, focus on critical paths |
| **Infrastructure** | 50%+ | Configuration and plumbing |
| **Overall Project** | 70%+ | Balanced coverage across all layers |

### Quality Gates

**Before Merging PR:**

- ‚úÖ All tests pass locally
- ‚úÖ All tests pass in CI/CD
- ‚úÖ Code coverage maintained or improved
- ‚úÖ No new flaky tests introduced
- ‚úÖ Test execution time reasonable (<15min for full suite)

**Before Release:**

- ‚úÖ All test suites green
- ‚úÖ E2E smoke tests pass in staging
- ‚úÖ Performance tests show no regression
- ‚úÖ AI agent tests validate quality
- ‚úÖ Manual smoke test checklist completed

---

## üõ†Ô∏è Testing Tools & Frameworks

### Primary Frameworks

#### xUnit (2.5.3 / 2.9.2)

Our test framework of choice for .NET.

```csharp
[Fact]  // Single test
public void SimpleTest() { }

[Theory]  // Parameterized test
[InlineData(1)]
[InlineData(2)]
public void ParameterizedTest(int value) { }
```

**Why xUnit?**

- Modern, actively maintained
- Excellent parallel execution
- Clean attribute syntax
- Strong community support

#### FluentAssertions (6.12.1 / 7.0.0)

Expressive, readable assertions.

```csharp
// Readable and descriptive
result.Should().NotBeNull();
list.Should().HaveCount(5)
    .And.Contain(x => x.Id == expectedId);
exception.Should().BeOfType<ArgumentNullException>()
    .Which.ParamName.Should().Be("studentId");

// Better error messages than Assert
// "Expected list to have 5 item(s), but found 3"
```

#### Moq (4.20.72)

Mocking framework for test doubles.

```csharp
var mockRepo = new Mock<IAssessmentRepository>();
mockRepo.Setup(r => r.GetByIdAsync(It.IsAny<Guid>(), default))
    .ReturnsAsync(new Assessment { /* ... */ });

// Verify method was called
mockRepo.Verify(r => r.SaveAsync(It.IsAny<Assessment>(), default), 
    Times.Once);
```

### Specialized Tools

#### Microsoft.AspNetCore.Mvc.Testing

WebApplicationFactory for integration testing APIs.

```csharp
public class ApiTests : IClassFixture<WebApplicationFactory<Program>>
{
    private readonly HttpClient client;
    
    public ApiTests(WebApplicationFactory<Program> factory)
    {
        client = factory.CreateClient();
    }
}
```

#### Microsoft.Playwright (1.48.0)

Browser automation for E2E tests.

```csharp
await using var browser = await playwright.Chromium.LaunchAsync();
var page = await browser.NewPageAsync();
await page.GotoAsync("https://localhost:5049");
await page.ClickAsync("text=Start Assessment");
```

#### coverlet

Code coverage collection (.NET native).

```bash
dotnet test --collect:"XPlat Code Coverage"
# Generates coverage.cobertura.xml
```

---

## üîÑ Test Execution Model

### Local Development

**Fast Feedback Loop:**

```
Code Change
    ‚Üì
Save File (Ctrl+S)
    ‚Üì
IDE Auto-Runs Affected Tests (<1s)
    ‚Üì
Green ‚úÖ ‚Üí Continue | Red ‚ùå ‚Üí Fix
```

**Pre-Commit:**

```bash
# Run all unit tests (~10s)
dotnet test tests/AcademicAssessment.Tests.Unit/

# If touching API:
dotnet test tests/AcademicAssessment.Tests.Integration/
```

### CI/CD Pipeline

```
Push/PR ‚Üí GitHub Actions
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Build & Unit Tests (3-5 min)       ‚îÇ
‚îÇ ‚Ä¢ dotnet build                      ‚îÇ
‚îÇ ‚Ä¢ Unit tests in parallel            ‚îÇ
‚îÇ ‚Ä¢ Coverage collection               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Integration Tests (5-10 min)       ‚îÇ
‚îÇ ‚Ä¢ PostgreSQL container              ‚îÇ
‚îÇ ‚Ä¢ Redis container                   ‚îÇ
‚îÇ ‚Ä¢ Database migrations               ‚îÇ
‚îÇ ‚Ä¢ API integration tests             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ E2E Tests (10-15 min)               ‚îÇ
‚îÇ ‚Ä¢ All services running              ‚îÇ
‚îÇ ‚Ä¢ Playwright browser tests          ‚îÇ
‚îÇ ‚Ä¢ Critical user workflows           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚úÖ All Green ‚Üí Merge Allowed
‚ùå Any Red ‚Üí Must Fix
```

---

## üìù Testing Conventions

### Test Naming

**Pattern:** `MethodName_StateUnderTest_ExpectedBehavior`

```csharp
// GOOD - Clear and descriptive
[Fact]
public void GetByIdAsync_ExistingId_ReturnsSuccess() { }

[Fact]
public void GetByIdAsync_NonExistentId_ReturnsNotFoundError() { }

[Fact]
public void CalculateScore_AllCorrectAnswers_Returns100Percent() { }

// AVOID - Ambiguous
[Fact]
public void TestGetById() { }

[Fact]
public void Test1() { }
```

### Test Structure (AAA Pattern)

**Arrange-Act-Assert** with explicit comments:

```csharp
[Fact]
public void Assessment_IsAdaptive_ReturnsTrueForAdaptiveType()
{
    // Arrange
    var assessment = new Assessment 
    { 
        Id = Guid.NewGuid(),
        AssessmentType = AssessmentType.Adaptive 
    };
    
    // Act
    var result = assessment.IsAdaptive;
    
    // Assert
    result.Should().BeTrue();
}
```

### Test Organization

Use `#region` to group related tests:

```csharp
public class AssessmentTests
{
    #region Test Helpers
    
    private static Assessment CreateTestAssessment() => new() 
    { 
        // ... 
    };
    
    #endregion
    
    #region Constructor Tests
    
    [Fact]
    public void Constructor_SetsAllProperties() { }
    
    #endregion
    
    #region Computed Property Tests
    
    [Fact]
    public void IsAdaptive_WhenAdaptiveType_ReturnsTrue() { }
    
    #endregion
}
```

---

## üéì Test-Driven Development (TDD)

While not strictly enforced, TDD is encouraged for:

- **New features** - Write test first to clarify requirements
- **Bug fixes** - Write failing test, then fix
- **Refactoring** - Tests provide safety net

### TDD Cycle

```
Red ‚Üí Green ‚Üí Refactor
 ‚Üì      ‚Üì       ‚Üì
Write  Make    Improve
Test   It      Code
       Pass
```

**Example TDD Workflow:**

```csharp
// 1. RED - Write failing test
[Fact]
public void CalculateProgress_CompletedAssessment_Returns100()
{
    var progress = ProgressCalculator.Calculate(totalQuestions: 10, answered: 10);
    progress.Should().Be(100.0);
}
// Test fails - method doesn't exist yet

// 2. GREEN - Implement minimum code to pass
public static double Calculate(int totalQuestions, int answered)
{
    return answered == totalQuestions ? 100.0 : 0.0;  // Simplest solution
}
// Test passes

// 3. REFACTOR - Improve implementation
public static double Calculate(int totalQuestions, int answered)
{
    if (totalQuestions <= 0) throw new ArgumentException(nameof(totalQuestions));
    return (answered / (double)totalQuestions) * 100.0;  // Proper calculation
}
// Test still passes, code is better
```

---

## üî¨ Test Categories

### Unit Tests (50% of suite)

**Scope:** Single class or method in isolation

**Characteristics:**

- ‚ö° Fast (<1ms per test)
- üîí Isolated (no external dependencies)
- üéØ Focused (one behavior per test)
- üìä High volume (many tests)

**What to Test:**

- Domain model behavior
- Business logic calculations
- Validation rules
- Algorithm correctness
- Edge cases and error handling

**Example:**

```csharp
[Fact]
public void Assessment_QuestionCount_ReturnsNumberOfQuestions()
{
    // Arrange
    var assessment = new Assessment 
    { 
        QuestionIds = new[] { Guid.NewGuid(), Guid.NewGuid() } 
    };
    
    // Act
    var count = assessment.QuestionCount;
    
    // Assert
    count.Should().Be(2);
}
```

### Integration Tests (30% of suite)

**Scope:** Multiple components working together

**Characteristics:**

- üêå Slower (100ms-1s per test)
- üîó Connected (uses real database, Redis)
- üéØ Broader (tests interactions)
- üìä Moderate volume

**What to Test:**

- API endpoints end-to-end
- Database operations
- Repository implementations
- Service integrations
- Error handling across layers

**Example:**

```csharp
[Fact]
public async Task GetAssessment_ExistingId_ReturnsOkWithData()
{
    // Arrange
    var client = factory.CreateClient();
    var id = await SeedTestAssessmentAsync();
    
    // Act
    var response = await client.GetAsync($"/api/v1/assessment/{id}");
    
    // Assert
    response.StatusCode.Should().Be(HttpStatusCode.OK);
    var assessment = await response.Content.ReadFromJsonAsync<Assessment>();
    assessment.Should().NotBeNull();
}
```

### E2E/UI Tests (5% of suite)

**Scope:** Complete user workflows

**Characteristics:**

- üê¢ Slow (10s-60s per test)
- üåê Full stack (all services + browser)
- üéØ Widest (critical paths only)
- üìä Low volume (expensive)

**What to Test:**

- Critical user journeys
- Multi-page workflows
- Authentication flows
- Error scenarios users see
- Cross-browser compatibility

**Example:**

```csharp
[Fact]
public async Task StudentTakesAssessment_EndToEnd_Success()
{
    // Student logs in, selects assessment, answers questions, submits, views results
    await page.GotoAsync("https://localhost:5049");
    await page.ClickAsync("text=Start Assessment");
    // ... multiple steps ...
    await page.ClickAsync("text=Submit");
    await Expect(page.Locator(".success-message")).ToBeVisibleAsync();
}
```

### AI/Agent Tests (15% of suite)

**Scope:** LLM integration and agent behavior

**Characteristics:**

- üêå Very slow (10s-120s per test)
- ü§ñ Requires Ollama
- üéØ Quality validation
- üìä Focused volume

**What to Test:**

- Question generation quality
- Feedback relevance
- Multi-agent orchestration
- Prompt effectiveness
- Response consistency

**Example:**

```bash
# Test Ollama integration
./tests/test-ollama-integration.sh

# Expected output:
# ‚úÖ Ollama service is running
# ‚úÖ Model llama3.2:3b is available
# ‚úÖ Question generation works
```

---

## üìà Test Metrics

### Key Metrics We Track

1. **Test Count:** ~1000+ tests total
2. **Execution Time:** <15 minutes full suite
3. **Code Coverage:** 70%+ overall
4. **Flaky Rate:** <1% (tests that randomly fail)
5. **PR Block Rate:** % of PRs blocked by test failures

### Coverage Analysis

Generated in CI/CD and viewable locally:

```bash
dotnet test --collect:"XPlat Code Coverage"

# Coverage report in:
# tests/*/TestResults/*/coverage.cobertura.xml
```

**Coverage Quality Over Quantity:**

- ‚úÖ 70% coverage of critical code > 90% coverage of trivial code
- ‚úÖ Test complex business logic thoroughly
- ‚úÖ Don't test framework code (EF, ASP.NET internals)
- ‚úÖ Focus on scenarios that can realistically break

---

## üö¶ Test Health

### Healthy Test Characteristics

- **Fast:** Unit tests <1ms, integration <1s, E2E <60s
- **Reliable:** Pass consistently (not flaky)
- **Isolated:** No dependencies on other tests
- **Readable:** Clear what's being tested
- **Maintainable:** Easy to update when code changes
- **Valuable:** Would catch real bugs

### Unhealthy Test Smells

‚ùå **Flaky tests** - Pass/fail randomly  
‚ùå **Slow tests** - Take too long to execute  
‚ùå **Brittle tests** - Break on unrelated changes  
‚ùå **Unclear tests** - Hard to understand what they test  
‚ùå **Redundant tests** - Multiple tests for same behavior  
‚ùå **Testing implementation** - Tests internal details, not behavior

### Test Debt Management

**Regular Maintenance:**

- Review flaky tests monthly
- Remove redundant tests
- Update tests when requirements change
- Refactor tests for clarity
- Keep test execution time under control

---

## üéØ Next Steps

### For New Developers

1. **Read this overview** ‚úÖ You're here!
2. **Set up local testing:** [02-local-testing.md](./02-local-testing.md)
3. **Learn unit testing:** [03-unit-testing.md](./03-unit-testing.md)
4. **Write your first test** using the patterns you've learned

### For Experienced Developers

- **Review specific guides** for your work:
  - API changes ‚Üí [04-integration-testing.md](./04-integration-testing.md)
  - UI features ‚Üí [05-e2e-testing.md](./05-e2e-testing.md)
  - AI agents ‚Üí [06-ai-agent-testing.md](./06-ai-agent-testing.md)
- **Check coverage:** [08-coverage.md](./08-coverage.md)
- **Optimize CI/CD:** [09-cicd-testing.md](./09-cicd-testing.md)

---

**Last Updated:** 2025-10-25  
**Related:** [README](./README.md) | [Local Testing](./02-local-testing.md) | [Unit Testing](./03-unit-testing.md)
